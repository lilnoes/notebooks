{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn generate names.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXJCevkpL8GcI+w29tU5MA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilnoes/notebooks/blob/main/rnn_generate_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLhO6NJ6fVAa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zgsIBKleNjK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "dfbec0a3-fa9e-4452-8018-da2464ea1880"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip && unzip data.zip && pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-30 06:46:46--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 52.84.16.73, 52.84.16.5, 52.84.16.104, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|52.84.16.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip             21%[===>                ] 599.29K  2.90MB/s               \rdata.zip            100%[===================>]   2.75M  9.08MB/s    in 0.3s    \n",
            "\n",
            "2020-06-30 06:46:47 (9.08 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GQiOX32gU64"
      },
      "source": [
        "data = Path('/content/data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKMQUgFzmHBu"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "import string\n",
        "letters = string.ascii_letters + \" .,-;'\"\n",
        "vocab_size = len(letters) + 1\n",
        "def uni_to_asci(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in letters)\n",
        "\n",
        "def process_word(word, shift=False):\n",
        "  word = uni_to_asci(word)\n",
        "  # word = re.sub(r'[^a-z]', '', word)\n",
        "  word = [letters.find(i) for i in word]\n",
        "  if shift:\n",
        "    word.append(len(letters))\n",
        "  return torch.tensor(word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D25RP0D3hGiu"
      },
      "source": [
        "def load_dataset(filedir):\n",
        "  categories = []\n",
        "  names_dict = {}\n",
        "  tensor_dict = {}\n",
        "  shifted_dict = {}\n",
        "  for filename in Path(filedir).glob('*.txt'):\n",
        "    cat = filename.stem\n",
        "    categories.append(cat)\n",
        "    lines = filename.read_text(encoding='utf-8').strip().split('\\n')\n",
        "    names_dict[cat] = lines\n",
        "    tensor_dict[cat] = [process_word(name) for name in lines]\n",
        "    shifted_dict[cat] = [process_word(name[1:], True) for name in lines]\n",
        "\n",
        "\n",
        "  return categories, names_dict, tensor_dict, shifted_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIUymPM6l4nw"
      },
      "source": [
        "categories, data_dict, tensor_dict, shifted_dict = load_dataset('/content/data/names')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpjCzucewgG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1af59f51-eb0d-452b-950b-5b7aca9fc924"
      },
      "source": [
        "x = process_word('emma')\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 12, 12,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR4hU_BIcYPV"
      },
      "source": [
        "import numpy as np\n",
        "def get_random():\n",
        "  np.random.seed()\n",
        "  i = np.random.randint(0, len(categories))\n",
        "  cat = categories[i]\n",
        "  j = np.random.randint(0, len(data_dict[cat]) )\n",
        "  name = data_dict[cat][j]\n",
        "  tensor = tensor_dict[cat][j]\n",
        "  shift = shifted_dict[cat][j]\n",
        "  return cat, torch.tensor([i]), name, tensor, shift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMu4xckG4HV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bf4daa4b-190c-454a-871c-28d98d9ac544"
      },
      "source": [
        "get_random()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Arabic',\n",
              " tensor([3]),\n",
              " 'Atiyeh',\n",
              " tensor([26, 19,  8, 24,  4,  7]),\n",
              " tensor([19,  8, 24,  4,  7, 58]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH3D6yuZz3CV"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, tx, units, batch_size, vocab_size):\n",
        "    super(Model, self).__init__()\n",
        "    self.units = units\n",
        "    self.batch_size = batch_size\n",
        "    self.tx = tx\n",
        "    self.embedding_letter = nn.Embedding(vocab_size, 128)\n",
        "    self.embedding_cat = nn.Embedding(len(categories), 32)\n",
        "    self.state = self.initialize_state()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.rnn = nn.GRUCell(input_size=128+32, hidden_size=units)\n",
        "    self.linear1 = nn.Linear(units, 64)\n",
        "    self.linear2 = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, cat, x, state, train=True):\n",
        "    cat = self.embedding_cat(cat)\n",
        "    # print(cat.shape)\n",
        "    x = torch.cat((self.embedding_letter(x), cat), dim=-1)\n",
        "    state = self.rnn(x, state)\n",
        "    x = F.dropout( F.relu( self.linear1(state), 0.2) )\n",
        "    x = self.linear2(x)\n",
        "    if not train:\n",
        "      return F.softmax(x, dim=-1), state\n",
        "    x = F.log_softmax(x, dim=-1)\n",
        "    return x, state\n",
        "    \n",
        "\n",
        "  def initialize_state(self):\n",
        "    return torch.zeros(self.batch_size, self.units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHExXAym8WYE"
      },
      "source": [
        "tx = vocab_size\n",
        "units = 256\n",
        "batch_size = 1\n",
        "vocab_size = vocab_size\n",
        "\n",
        "model = Model(tx, units, batch_size, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCIdY5KZEa9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b1bdfcab-8d9c-4764-be3d-4d89bb6168c6"
      },
      "source": [
        "cat, catx, name, tensor, shift = get_random()\n",
        "# tensor = model.get_embedding(tensor)\n",
        "state = model.initialize_state()\n",
        "y, _= model(catx, tensor[0].view(1),state)\n",
        "print(y)\n",
        "# print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32])\n",
            "tensor([[-3.9879, -4.0923, -4.0870, -4.2259, -4.1210, -4.0089, -4.0537, -4.0829,\n",
            "         -4.0913, -4.0510, -4.0314, -3.9797, -4.0686, -4.1866, -4.0586, -4.2074,\n",
            "         -4.0101, -4.1678, -3.9693, -4.1856, -4.1325, -4.0690, -4.1766, -4.1277,\n",
            "         -4.0724, -4.1148, -4.0171, -3.9162, -4.1556, -4.0791, -4.0098, -4.1327,\n",
            "         -3.9420, -3.9905, -4.0899, -4.1620, -4.0165, -4.0605, -4.0727, -3.9840,\n",
            "         -4.1216, -4.0531, -4.1733, -4.1897, -4.0925, -4.0279, -4.0463, -4.0862,\n",
            "         -4.1765, -4.0428, -4.1337, -4.0614, -4.1824, -3.9716, -3.9224, -4.1788,\n",
            "         -3.9922, -4.1719, -4.1321]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Yw0tCzFsFv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "891b70cf-4f22-44c4-f6ab-cc8c27e8999a"
      },
      "source": [
        "loss_fn(y, shift[0].view(1))\n",
        "# y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.9879, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsdYYlYgd4d"
      },
      "source": [
        "loss_fn = nn.NLLLoss()\n",
        "model = Model(tx, units, batch_size, vocab_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "istate = model.initialize_state()\n",
        "def train_step(cat, x, y):\n",
        "  state = istate\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "  for i in range(x.size(0)):\n",
        "    out, state = model(cat, x[i].view(1), state)\n",
        "    loss += loss_fn(out, y[i].view(1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()/x.size(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hLlF9N_j8SM"
      },
      "source": [
        "def train(epochs, steps=1000):\n",
        "  count = 1\n",
        "  for epoch in range(epochs):\n",
        "    batch_loss = 0\n",
        "    for step in range(steps):\n",
        "      count += 1\n",
        "      _,catx,_,x,y = get_random()\n",
        "      batch_loss += train_step(catx, x, y)\n",
        "      if count %100==0:\n",
        "        rid = np.random.randint(0, len(categories))\n",
        "        letter = np.random.randint(26, 52)\n",
        "        print('Evaluation ', evaluate(rid, letters[letter]))\n",
        "        print('Evaluation 1', evaluate(rid, letters[letter]))\n",
        "        print('Evaluation 0.5', evaluate1(rid, letters[letter]), 0.5)\n",
        "        print('Evaluation 0.75', evaluate1(rid, letters[letter]), 0.75)\n",
        "        print('Evaluation 0.25', evaluate1(rid, letters[letter]), 0.25)\n",
        "    print(f'epoch {epoch+1} loss {batch_loss/steps:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQYHBbpns_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57dccb35-a48d-4d3b-b5b2-a69e511b2e46"
      },
      "source": [
        "train(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation  ('Irish', 'Xand')\n",
            "Evaluation 1 ('Irish', 'Xinghe')\n",
            "Evaluation 0.5 ('Irish', 'Xanghona') 0.5\n",
            "Evaluation 0.75 ('Irish', 'Xemgeon') 0.75\n",
            "Evaluation 0.25 ('Irish', 'Xinner') 0.25\n",
            "Evaluation  ('Portuguese', 'Dara')\n",
            "Evaluation 1 ('Portuguese', 'Darro')\n",
            "Evaluation 0.5 ('Portuguese', 'Datca') 0.5\n",
            "Evaluation 0.75 ('Portuguese', 'Das') 0.75\n",
            "Evaluation 0.25 ('Portuguese', \"D'egrijes\") 0.25\n",
            "Evaluation  ('Greek', 'Quras')\n",
            "Evaluation 1 ('Greek', 'Quralis')\n",
            "Evaluation 0.5 ('Greek', 'Qudes') 0.5\n",
            "Evaluation 0.75 ('Greek', 'Qupis') 0.75\n",
            "Evaluation 0.25 ('Greek', 'Quttalarigos') 0.25\n",
            "Evaluation  ('Spanish', 'Xarak')\n",
            "Evaluation 1 ('Spanish', 'Xarcha')\n",
            "Evaluation 0.5 ('Spanish', 'Xures') 0.5\n",
            "Evaluation 0.75 ('Spanish', 'Xari') 0.75\n",
            "Evaluation 0.25 ('Spanish', 'Xonma') 0.25\n",
            "Evaluation  ('German', 'Yoman')\n",
            "Evaluation 1 ('German', 'Yous')\n",
            "Evaluation 0.5 ('German', 'Yhin') 0.5\n",
            "Evaluation 0.75 ('German', 'Yaurogs') 0.75\n",
            "Evaluation 0.25 ('German', 'Yeilt') 0.25\n",
            "Evaluation  ('Vietnamese', 'Rhin')\n",
            "Evaluation 1 ('Vietnamese', 'Rya')\n",
            "Evaluation 0.5 ('Vietnamese', 'Ro') 0.5\n",
            "Evaluation 0.75 ('Vietnamese', 'Rian') 0.75\n",
            "Evaluation 0.25 ('Vietnamese', 'Roo') 0.25\n",
            "Evaluation  ('German', 'Fander')\n",
            "Evaluation 1 ('German', 'Frun')\n",
            "Evaluation 0.5 ('German', 'Fuias') 0.5\n",
            "Evaluation 0.75 ('German', 'Fonvert') 0.75\n",
            "Evaluation 0.25 ('German', 'Frindar') 0.25\n",
            "Evaluation  ('Scottish', 'Vand')\n",
            "Evaluation 1 ('Scottish', 'Ville')\n",
            "Evaluation 0.5 ('Scottish', 'Vuck') 0.5\n",
            "Evaluation 0.75 ('Scottish', 'Venghacy') 0.75\n",
            "Evaluation 0.25 ('Scottish', 'Villes') 0.25\n",
            "Evaluation  ('Polish', 'Quernienski')\n",
            "Evaluation 1 ('Polish', 'Qurunez')\n",
            "Evaluation 0.5 ('Polish', 'Qunek') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Qorpasku') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Qurckomodkiewems') 0.25\n",
            "Evaluation  ('Chinese', 'Han')\n",
            "Evaluation 1 ('Chinese', 'Han')\n",
            "Evaluation 0.5 ('Chinese', 'Hu') 0.5\n",
            "Evaluation 0.75 ('Chinese', 'Hu') 0.75\n",
            "Evaluation 0.25 ('Chinese', 'Han') 0.25\n",
            "epoch 1 loss 2.002\n",
            "Evaluation  ('German', 'Schlander')\n",
            "Evaluation 1 ('German', 'Schrander')\n",
            "Evaluation 0.5 ('German', 'Sacchdt') 0.5\n",
            "Evaluation 0.75 ('German', 'Snogdreiley') 0.75\n",
            "Evaluation 0.25 ('German', 'Swasp') 0.25\n",
            "Evaluation  ('Arabic', 'Chasse')\n",
            "Evaluation 1 ('Arabic', 'Char')\n",
            "Evaluation 0.5 ('Arabic', 'Cahdal') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Cherhoul') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Chahrou') 0.25\n",
            "Evaluation  ('Dutch', 'Lonran')\n",
            "Evaluation 1 ('Dutch', 'Lonren')\n",
            "Evaluation 0.5 ('Dutch', 'Laclovil') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Leuwer') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Leujzbondez') 0.25\n",
            "Evaluation  ('Korean', 'O')\n",
            "Evaluation 1 ('Korean', 'Oh')\n",
            "Evaluation 0.5 ('Korean', 'Oh') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Oon') 0.75\n",
            "Evaluation 0.25 ('Korean', 'O') 0.25\n",
            "Evaluation  ('English', 'Ednen')\n",
            "Evaluation 1 ('English', 'Eston')\n",
            "Evaluation 0.5 ('English', 'Elnran') 0.5\n",
            "Evaluation 0.75 ('English', 'Essorn') 0.75\n",
            "Evaluation 0.25 ('English', 'Eagla') 0.25\n",
            "Evaluation  ('Greek', 'Rullis')\n",
            "Evaluation 1 ('Greek', 'Raskas')\n",
            "Evaluation 0.5 ('Greek', 'Rakolis') 0.5\n",
            "Evaluation 0.75 ('Greek', 'Rumnas') 0.75\n",
            "Evaluation 0.25 ('Greek', 'Raidos') 0.25\n",
            "Evaluation  ('Scottish', 'Isson')\n",
            "Evaluation 1 ('Scottish', 'Irnan')\n",
            "Evaluation 0.5 ('Scottish', 'Ifroon') 0.5\n",
            "Evaluation 0.75 ('Scottish', 'Irllov') 0.75\n",
            "Evaluation 0.25 ('Scottish', 'Ikerson') 0.25\n",
            "Evaluation  ('Polish', 'Charba')\n",
            "Evaluation 1 ('Polish', 'Chienganski')\n",
            "Evaluation 0.5 ('Polish', 'Corka') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Chrwimpkorsk') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Chhak') 0.25\n",
            "Evaluation  ('Portuguese', 'Oar')\n",
            "Evaluation 1 ('Portuguese', 'Orani')\n",
            "Evaluation 0.5 ('Portuguese', 'Orahii') 0.5\n",
            "Evaluation 0.75 ('Portuguese', 'Oize') 0.75\n",
            "Evaluation 0.25 ('Portuguese', 'Oreye') 0.25\n",
            "Evaluation  ('Polish', 'Owak')\n",
            "Evaluation 1 ('Polish', 'Okar')\n",
            "Evaluation 0.5 ('Polish', 'O-rretse') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Obanoersko') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Ouczazk') 0.25\n",
            "epoch 2 loss 1.953\n",
            "Evaluation  ('Dutch', 'Een')\n",
            "Evaluation 1 ('Dutch', 'Essen')\n",
            "Evaluation 0.5 ('Dutch', 'Ettja') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Eack') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Eslam') 0.25\n",
            "Evaluation  ('English', 'Quur')\n",
            "Evaluation 1 ('English', 'Qurang')\n",
            "Evaluation 0.5 ('English', 'Qower') 0.5\n",
            "Evaluation 0.75 ('English', 'Qulger') 0.75\n",
            "Evaluation 0.25 ('English', 'Quusvell') 0.25\n",
            "Evaluation  ('Polish', 'Paka')\n",
            "Evaluation 1 ('Polish', 'Pakan')\n",
            "Evaluation 0.5 ('Polish', 'Piana') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Padasin') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Pothedkanak') 0.25\n",
            "Evaluation  ('Arabic', 'Rakas')\n",
            "Evaluation 1 ('Arabic', 'Rasa')\n",
            "Evaluation 0.5 ('Arabic', 'Rurios') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Ronyih') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Riukpou') 0.25\n",
            "Evaluation  ('Czech', 'Aman')\n",
            "Evaluation 1 ('Czech', 'Adar')\n",
            "Evaluation 0.5 ('Czech', 'Agsoattn') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Amakason') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Amat') 0.25\n",
            "Evaluation  ('Polish', 'Kowek')\n",
            "Evaluation 1 ('Polish', 'Kok')\n",
            "Evaluation 0.5 ('Polish', 'Konaek') 0.5\n",
            "Evaluation 0.75 ('Polish', \"Kemr'an\") 0.75\n",
            "Evaluation 0.25 ('Polish', 'Kliton') 0.25\n",
            "Evaluation  ('Polish', 'Kill')\n",
            "Evaluation 1 ('Polish', 'Kowazk')\n",
            "Evaluation 0.5 ('Polish', 'Keog') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Kaclimka') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Kuzyckk') 0.25\n",
            "Evaluation  ('French', 'Casser')\n",
            "Evaluation 1 ('French', 'Chaus')\n",
            "Evaluation 0.5 ('French', 'Chaditon') 0.5\n",
            "Evaluation 0.75 ('French', 'Cenreye') 0.75\n",
            "Evaluation 0.25 ('French', 'Castesdorili') 0.25\n",
            "Evaluation  ('French', 'Harnar')\n",
            "Evaluation 1 ('French', 'Harner')\n",
            "Evaluation 0.5 ('French', 'Hertant') 0.5\n",
            "Evaluation 0.75 ('French', 'Harire') 0.75\n",
            "Evaluation 0.25 ('French', 'Hawer') 0.25\n",
            "Evaluation  ('Korean', 'Leo')\n",
            "Evaluation 1 ('Korean', 'La')\n",
            "Evaluation 0.5 ('Korean', 'Ley') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Leun') 0.75\n",
            "Evaluation 0.25 ('Korean', 'Lin') 0.25\n",
            "epoch 3 loss 1.967\n",
            "Evaluation  ('French', 'Vicher')\n",
            "Evaluation 1 ('French', 'Villin')\n",
            "Evaluation 0.5 ('French', 'Vacoy') 0.5\n",
            "Evaluation 0.75 ('French', 'Vili') 0.75\n",
            "Evaluation 0.25 ('French', 'Virmermor') 0.25\n",
            "Evaluation  ('Korean', 'Ma')\n",
            "Evaluation 1 ('Korean', 'Mis')\n",
            "Evaluation 0.5 ('Korean', 'Mo') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Mao') 0.75\n",
            "Evaluation 0.25 ('Korean', 'Msong') 0.25\n",
            "Evaluation  ('English', 'Can')\n",
            "Evaluation 1 ('English', 'Calle')\n",
            "Evaluation 0.5 ('English', 'Cla') 0.5\n",
            "Evaluation 0.75 ('English', 'Ceerrell') 0.75\n",
            "Evaluation 0.25 ('English', 'Caprite') 0.25\n",
            "Evaluation  ('Japanese', 'Ganguka')\n",
            "Evaluation 1 ('Japanese', 'Gakara')\n",
            "Evaluation 0.5 ('Japanese', 'Gokene') 0.5\n",
            "Evaluation 0.75 ('Japanese', 'Gudomiri') 0.75\n",
            "Evaluation 0.25 ('Japanese', 'Ga') 0.25\n",
            "Evaluation  ('German', 'Schrusse')\n",
            "Evaluation 1 ('German', 'Schuder')\n",
            "Evaluation 0.5 ('German', 'Schuvat') 0.5\n",
            "Evaluation 0.75 ('German', 'Suklder') 0.75\n",
            "Evaluation 0.25 ('German', 'Saumilar') 0.25\n",
            "Evaluation  ('Spanish', 'Kondez')\n",
            "Evaluation 1 ('Spanish', 'Kone')\n",
            "Evaluation 0.5 ('Spanish', 'Ke') 0.5\n",
            "Evaluation 0.75 ('Spanish', 'Kimo') 0.75\n",
            "Evaluation 0.25 ('Spanish', 'Kanmanas') 0.25\n",
            "Evaluation  ('Arabic', 'Kassa')\n",
            "Evaluation 1 ('Arabic', 'Khassa')\n",
            "Evaluation 0.5 ('Arabic', 'Kaldan') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Koud') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Kharb') 0.25\n",
            "Evaluation  ('German', 'Tasser')\n",
            "Evaluation 1 ('German', 'Trorder')\n",
            "Evaluation 0.5 ('German', 'Touarder') 0.5\n",
            "Evaluation 0.75 ('German', 'Timtoan') 0.75\n",
            "Evaluation 0.25 ('German', 'Tahuolh') 0.25\n",
            "Evaluation  ('Italian', 'Narra')\n",
            "Evaluation 1 ('Italian', 'Nardono')\n",
            "Evaluation 0.5 ('Italian', 'Narkigdicka') 0.5\n",
            "Evaluation 0.75 ('Italian', 'Namodu') 0.75\n",
            "Evaluation 0.25 ('Italian', 'Noumgulsena') 0.25\n",
            "Evaluation  ('Italian', 'Bardi')\n",
            "Evaluation 1 ('Italian', 'Barta')\n",
            "Evaluation 0.5 ('Italian', 'Bervatenti') 0.5\n",
            "Evaluation 0.75 ('Italian', 'Baverlondo') 0.75\n",
            "Evaluation 0.25 ('Italian', 'Barlimumet') 0.25\n",
            "epoch 4 loss 1.937\n",
            "Evaluation  ('Vietnamese', 'Chu')\n",
            "Evaluation 1 ('Vietnamese', 'Chu')\n",
            "Evaluation 0.5 ('Vietnamese', 'Chu') 0.5\n",
            "Evaluation 0.75 ('Vietnamese', 'Chu') 0.75\n",
            "Evaluation 0.25 ('Vietnamese', 'Chung') 0.25\n",
            "Evaluation  ('Korean', 'Pan')\n",
            "Evaluation 1 ('Korean', 'Pan')\n",
            "Evaluation 0.5 ('Korean', 'Pasnon') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Pawki') 0.75\n",
            "Evaluation 0.25 ('Korean', 'Piidnimo') 0.25\n",
            "Evaluation  ('Spanish', 'Zareno')\n",
            "Evaluation 1 ('Spanish', 'Zareno')\n",
            "Evaluation 0.5 ('Spanish', 'Zelvollansa') 0.5\n",
            "Evaluation 0.75 ('Spanish', 'Zerbenrie') 0.75\n",
            "Evaluation 0.25 ('Spanish', 'Zaloso') 0.25\n",
            "Evaluation  ('Japanese', 'Hano')\n",
            "Evaluation 1 ('Japanese', 'Haka')\n",
            "Evaluation 0.5 ('Japanese', 'Hochikazanio') 0.5\n",
            "Evaluation 0.75 ('Japanese', 'Hagete') 0.75\n",
            "Evaluation 0.25 ('Japanese', 'Hadeboro') 0.25\n",
            "Evaluation  ('English', 'Gran')\n",
            "Evaluation 1 ('English', 'Gartan')\n",
            "Evaluation 0.5 ('English', 'Giolahhe') 0.5\n",
            "Evaluation 0.75 ('English', 'Grahmitk') 0.75\n",
            "Evaluation 0.25 ('English', 'Gassean') 0.25\n",
            "Evaluation  ('Russian', 'Avanesky')\n",
            "Evaluation 1 ('Russian', 'Ader')\n",
            "Evaluation 0.5 ('Russian', 'A') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Aachalddima') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Abeimuy') 0.25\n",
            "Evaluation  ('Chinese', 'Chau')\n",
            "Evaluation 1 ('Chinese', 'Cha')\n",
            "Evaluation 0.5 ('Chinese', 'Chgih') 0.5\n",
            "Evaluation 0.75 ('Chinese', 'Che') 0.75\n",
            "Evaluation 0.25 ('Chinese', 'Chang') 0.25\n",
            "Evaluation  ('Arabic', 'Chanaz')\n",
            "Evaluation 1 ('Arabic', 'Challos')\n",
            "Evaluation 0.5 ('Arabic', 'Charmi') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Chantouk') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Ch') 0.25\n",
            "Evaluation  ('Scottish', 'Rostell')\n",
            "Evaluation 1 ('Scottish', 'Ritton')\n",
            "Evaluation 0.5 ('Scottish', 'Rinsonte') 0.5\n",
            "Evaluation 0.75 ('Scottish', 'Raz') 0.75\n",
            "Evaluation 0.25 ('Scottish', 'Ritcos') 0.25\n",
            "Evaluation  ('French', 'Zerrier')\n",
            "Evaluation 1 ('French', 'Zarnar')\n",
            "Evaluation 0.5 ('French', 'Zrevessanheunett') 0.5\n",
            "Evaluation 0.75 ('French', 'Zotouberouv') 0.75\n",
            "Evaluation 0.25 ('French', 'Zheuvon') 0.25\n",
            "epoch 5 loss 1.935\n",
            "Evaluation  ('Chinese', 'Pang')\n",
            "Evaluation 1 ('Chinese', 'Pang')\n",
            "Evaluation 0.5 ('Chinese', 'Phoies') 0.5\n",
            "Evaluation 0.75 ('Chinese', 'Pand') 0.75\n",
            "Evaluation 0.25 ('Chinese', 'Panr') 0.25\n",
            "Evaluation  ('French', 'Jassen')\n",
            "Evaluation 1 ('French', 'Ja')\n",
            "Evaluation 0.5 ('French', 'Jicemrans') 0.5\n",
            "Evaluation 0.75 ('French', 'Joou') 0.75\n",
            "Evaluation 0.25 ('French', 'Janpue') 0.25\n",
            "Evaluation  ('Czech', 'Pareva')\n",
            "Evaluation 1 ('Czech', 'Parna')\n",
            "Evaluation 0.5 ('Czech', 'Paz') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Pilmoy') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Parsek') 0.25\n",
            "Evaluation  ('Vietnamese', 'Quinh')\n",
            "Evaluation 1 ('Vietnamese', 'Quang')\n",
            "Evaluation 0.5 ('Vietnamese', 'Quaur') 0.5\n",
            "Evaluation 0.75 ('Vietnamese', 'Quaw') 0.75\n",
            "Evaluation 0.25 ('Vietnamese', 'Qui') 0.25\n",
            "Evaluation  ('Czech', 'Iszer')\n",
            "Evaluation 1 ('Czech', 'Ista')\n",
            "Evaluation 0.5 ('Czech', 'Isa') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Issqin') 0.75\n",
            "Evaluation 0.25 ('Czech', 'I') 0.25\n",
            "Evaluation  ('Russian', 'Jarlinsky')\n",
            "Evaluation 1 ('Russian', 'Jankin')\n",
            "Evaluation 0.5 ('Russian', 'Jetzanev') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Jankicherkh') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Jinta') 0.25\n",
            "Evaluation  ('Irish', 'Ine')\n",
            "Evaluation 1 ('Irish', 'Is')\n",
            "Evaluation 0.5 ('Irish', 'Inin') 0.5\n",
            "Evaluation 0.75 ('Irish', 'Imarn') 0.75\n",
            "Evaluation 0.25 ('Irish', 'Indronz') 0.25\n",
            "Evaluation  ('Czech', 'Zarek')\n",
            "Evaluation 1 ('Czech', 'Zara')\n",
            "Evaluation 0.5 ('Czech', 'Zyovo') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Zolazski') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Zihxe') 0.25\n",
            "Evaluation  ('Russian', 'Charcharov')\n",
            "Evaluation 1 ('Russian', 'Chinthak')\n",
            "Evaluation 0.5 ('Russian', 'Cochholsa') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Caolin') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Chochy') 0.25\n",
            "Evaluation  ('Dutch', 'Qurneirs')\n",
            "Evaluation 1 ('Dutch', 'Quren')\n",
            "Evaluation 0.5 ('Dutch', 'Qurim') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Quugrers') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Quyren') 0.25\n",
            "epoch 6 loss 1.931\n",
            "Evaluation  ('Scottish', 'Xint')\n",
            "Evaluation 1 ('Scottish', 'Xindro')\n",
            "Evaluation 0.5 ('Scottish', 'Xnort') 0.5\n",
            "Evaluation 0.75 ('Scottish', 'Xord') 0.75\n",
            "Evaluation 0.25 ('Scottish', 'Xcndall') 0.25\n",
            "Evaluation  ('Japanese', 'Da')\n",
            "Evaluation 1 ('Japanese', 'Da')\n",
            "Evaluation 0.5 ('Japanese', 'Dimya') 0.5\n",
            "Evaluation 0.75 ('Japanese', 'Dhiiryi') 0.75\n",
            "Evaluation 0.25 ('Japanese', 'Da') 0.25\n",
            "Evaluation  ('Dutch', 'Lants')\n",
            "Evaluation 1 ('Dutch', 'Lanners')\n",
            "Evaluation 0.5 ('Dutch', 'Liks') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Lijsl') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Lenze') 0.25\n",
            "Evaluation  ('Russian', 'Darinov')\n",
            "Evaluation 1 ('Russian', 'Dantsov')\n",
            "Evaluation 0.5 ('Russian', 'Dadjimichaj') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Doeahav') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Dadykivstz') 0.25\n",
            "Evaluation  ('Portuguese', 'Yama')\n",
            "Evaluation 1 ('Portuguese', 'Yos')\n",
            "Evaluation 0.5 ('Portuguese', 'Yatieu') 0.5\n",
            "Evaluation 0.75 ('Portuguese', 'Yanges') 0.75\n",
            "Evaluation 0.25 ('Portuguese', 'Yharai') 0.25\n",
            "Evaluation  ('Czech', 'Barton')\n",
            "Evaluation 1 ('Czech', 'Bashar')\n",
            "Evaluation 0.5 ('Czech', 'Bterrrersovungor') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Boochak') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Baylir') 0.25\n",
            "Evaluation  ('Korean', 'Ma')\n",
            "Evaluation 1 ('Korean', 'Mo')\n",
            "Evaluation 0.5 ('Korean', 'Mo') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Meu') 0.75\n",
            "Evaluation 0.25 ('Korean', 'Mo') 0.25\n",
            "Evaluation  ('English', 'Esten')\n",
            "Evaluation 1 ('English', 'Eunter')\n",
            "Evaluation 0.5 ('English', 'Ennisofs') 0.5\n",
            "Evaluation 0.75 ('English', 'Eerpicy') 0.75\n",
            "Evaluation 0.25 ('English', 'E') 0.25\n",
            "Evaluation  ('Italian', 'Ira')\n",
            "Evaluation 1 ('Italian', 'Iri')\n",
            "Evaluation 0.5 ('Italian', 'Ikunnylo') 0.5\n",
            "Evaluation 0.75 ('Italian', 'Iito') 0.75\n",
            "Evaluation 0.25 ('Italian', 'Iselce') 0.25\n",
            "Evaluation  ('German', 'Marner')\n",
            "Evaluation 1 ('German', 'Mannar')\n",
            "Evaluation 0.5 ('German', 'Mebimhuder') 0.5\n",
            "Evaluation 0.75 ('German', 'Muk') 0.75\n",
            "Evaluation 0.25 ('German', 'Machetraozd') 0.25\n",
            "epoch 7 loss 1.894\n",
            "Evaluation  ('Polish', 'Vartky')\n",
            "Evaluation 1 ('Polish', 'Vaski')\n",
            "Evaluation 0.5 ('Polish', 'Vowski') 0.5\n",
            "Evaluation 0.75 ('Polish', 'Votmeidy') 0.75\n",
            "Evaluation 0.25 ('Polish', 'Vavicka') 0.25\n",
            "Evaluation  ('Korean', 'Ang')\n",
            "Evaluation 1 ('Korean', 'Ang')\n",
            "Evaluation 0.5 ('Korean', 'Am') 0.5\n",
            "Evaluation 0.75 ('Korean', 'Amjan') 0.75\n",
            "Evaluation 0.25 ('Korean', 'Aukkan') 0.25\n",
            "Evaluation  ('Japanese', 'Antaka')\n",
            "Evaluation 1 ('Japanese', 'Akana')\n",
            "Evaluation 0.5 ('Japanese', 'Asuraka') 0.5\n",
            "Evaluation 0.75 ('Japanese', 'Aloguwa') 0.75\n",
            "Evaluation 0.25 ('Japanese', 'Agomaki') 0.25\n",
            "Evaluation  ('Dutch', 'Gromoes')\n",
            "Evaluation 1 ('Dutch', 'Gerner')\n",
            "Evaluation 0.5 ('Dutch', 'Gelsad') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Garrenson') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Goter') 0.25\n",
            "Evaluation  ('Greek', 'Vales')\n",
            "Evaluation 1 ('Greek', 'Vistakos')\n",
            "Evaluation 0.5 ('Greek', 'Vredogopoulos') 0.5\n",
            "Evaluation 0.75 ('Greek', 'Voslagaros') 0.75\n",
            "Evaluation 0.25 ('Greek', 'Vorocos') 0.25\n",
            "Evaluation  ('German', 'Lentversner')\n",
            "Evaluation 1 ('German', 'Laudenz')\n",
            "Evaluation 0.5 ('German', 'Leniatet') 0.5\n",
            "Evaluation 0.75 ('German', 'Lampe') 0.75\n",
            "Evaluation 0.25 ('German', 'Leyer') 0.25\n",
            "Evaluation  ('French', 'Charro')\n",
            "Evaluation 1 ('French', 'Charnin')\n",
            "Evaluation 0.5 ('French', 'Clenu') 0.5\n",
            "Evaluation 0.75 ('French', 'Chernoess') 0.75\n",
            "Evaluation 0.25 ('French', 'Comille') 0.25\n",
            "Evaluation  ('Arabic', 'Chastanh')\n",
            "Evaluation 1 ('Arabic', 'Chas')\n",
            "Evaluation 0.5 ('Arabic', 'Chukhar') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Chankos') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Chandis') 0.25\n",
            "Evaluation  ('Greek', 'Lostonos')\n",
            "Evaluation 1 ('Greek', 'Lostani')\n",
            "Evaluation 0.5 ('Greek', 'Lolanikis') 0.5\n",
            "Evaluation 0.75 ('Greek', 'Ladoulis') 0.75\n",
            "Evaluation 0.25 ('Greek', 'Lilos') 0.25\n",
            "Evaluation  ('Czech', 'Yan')\n",
            "Evaluation 1 ('Czech', 'Yan')\n",
            "Evaluation 0.5 ('Czech', 'Yesthaakon') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Yikalsugek') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Yagiefa') 0.25\n",
            "epoch 8 loss 1.904\n",
            "Evaluation  ('Dutch', 'Ferner')\n",
            "Evaluation 1 ('Dutch', 'Fender')\n",
            "Evaluation 0.5 ('Dutch', 'Finn') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Ferger') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Farswers') 0.25\n",
            "Evaluation  ('French', 'Carton')\n",
            "Evaluation 1 ('French', 'Charnit')\n",
            "Evaluation 0.5 ('French', 'Chan nopon') 0.5\n",
            "Evaluation 0.75 ('French', 'Cherleay') 0.75\n",
            "Evaluation 0.25 ('French', 'Camalors') 0.25\n",
            "Evaluation  ('Arabic', 'Danes')\n",
            "Evaluation 1 ('Arabic', 'Dan')\n",
            "Evaluation 0.5 ('Arabic', 'D') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Dimari') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Dhat') 0.25\n",
            "Evaluation  ('Arabic', 'Vanta')\n",
            "Evaluation 1 ('Arabic', 'Vakhiski')\n",
            "Evaluation 0.5 ('Arabic', 'Voul') 0.5\n",
            "Evaluation 0.75 ('Arabic', 'Vatha') 0.75\n",
            "Evaluation 0.25 ('Arabic', 'Vahari') 0.25\n",
            "Evaluation  ('German', 'Zen')\n",
            "Evaluation 1 ('German', 'Zang')\n",
            "Evaluation 0.5 ('German', 'Zuch') 0.5\n",
            "Evaluation 0.75 ('German', 'Zhikan') 0.75\n",
            "Evaluation 0.25 ('German', 'Zouen') 0.25\n",
            "Evaluation  ('Spanish', 'Urinez')\n",
            "Evaluation 1 ('Spanish', 'Ulla')\n",
            "Evaluation 0.5 ('Spanish', 'Ulacteri') 0.5\n",
            "Evaluation 0.75 ('Spanish', 'Umaines') 0.75\n",
            "Evaluation 0.25 ('Spanish', 'Urcusfilla') 0.25\n",
            "Evaluation  ('Portuguese', 'Irao')\n",
            "Evaluation 1 ('Portuguese', 'Isures')\n",
            "Evaluation 0.5 ('Portuguese', 'Iolo') 0.5\n",
            "Evaluation 0.75 ('Portuguese', 'Iaure') 0.75\n",
            "Evaluation 0.25 ('Portuguese', 'Iray') 0.25\n",
            "Evaluation  ('Russian', 'Panter')\n",
            "Evaluation 1 ('Russian', 'Partza')\n",
            "Evaluation 0.5 ('Russian', 'Pono') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Pelhakov') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Parthansihov') 0.25\n",
            "Evaluation  ('Dutch', 'Lerd')\n",
            "Evaluation 1 ('Dutch', 'Loher')\n",
            "Evaluation 0.5 ('Dutch', 'Lerszack') 0.5\n",
            "Evaluation 0.75 ('Dutch', 'Luiy') 0.75\n",
            "Evaluation 0.25 ('Dutch', 'Leiudders') 0.25\n",
            "Evaluation  ('Chinese', 'Ian')\n",
            "Evaluation 1 ('Chinese', 'Igg')\n",
            "Evaluation 0.5 ('Chinese', 'I') 0.5\n",
            "Evaluation 0.75 ('Chinese', 'Igeg') 0.75\n",
            "Evaluation 0.25 ('Chinese', 'Ieu') 0.25\n",
            "epoch 9 loss 1.896\n",
            "Evaluation  ('Japanese', 'Xishi')\n",
            "Evaluation 1 ('Japanese', 'Xakana')\n",
            "Evaluation 0.5 ('Japanese', 'Xotomo') 0.5\n",
            "Evaluation 0.75 ('Japanese', 'Xiursi') 0.75\n",
            "Evaluation 0.25 ('Japanese', 'Xatosa') 0.25\n",
            "Evaluation  ('Scottish', 'Millan')\n",
            "Evaluation 1 ('Scottish', 'Mckay')\n",
            "Evaluation 0.5 ('Scottish', 'Magterans') 0.5\n",
            "Evaluation 0.75 ('Scottish', 'Manederus') 0.75\n",
            "Evaluation 0.25 ('Scottish', 'Mintrude') 0.25\n",
            "Evaluation  ('Spanish', 'Ronari')\n",
            "Evaluation 1 ('Spanish', 'Roto')\n",
            "Evaluation 0.5 ('Spanish', 'Rosleil') 0.5\n",
            "Evaluation 0.75 ('Spanish', 'Rong') 0.75\n",
            "Evaluation 0.25 ('Spanish', 'RuBanto') 0.25\n",
            "Evaluation  ('French', 'Eunane')\n",
            "Evaluation 1 ('French', 'Eunis')\n",
            "Evaluation 0.5 ('French', 'Euuton') 0.5\n",
            "Evaluation 0.75 ('French', 'Euyon') 0.75\n",
            "Evaluation 0.25 ('French', 'Eumesih') 0.25\n",
            "Evaluation  ('Chinese', 'Ki')\n",
            "Evaluation 1 ('Chinese', 'Kwen')\n",
            "Evaluation 0.5 ('Chinese', 'Kel') 0.5\n",
            "Evaluation 0.75 ('Chinese', 'Koi') 0.75\n",
            "Evaluation 0.25 ('Chinese', 'Kau') 0.25\n",
            "Evaluation  ('Vietnamese', 'Es')\n",
            "Evaluation 1 ('Vietnamese', 'E')\n",
            "Evaluation 0.5 ('Vietnamese', 'Eu') 0.5\n",
            "Evaluation 0.75 ('Vietnamese', 'Eh') 0.75\n",
            "Evaluation 0.25 ('Vietnamese', 'E') 0.25\n",
            "Evaluation  ('Italian', 'Vikas')\n",
            "Evaluation 1 ('Italian', 'Vilni')\n",
            "Evaluation 0.5 ('Italian', 'Vinari') 0.5\n",
            "Evaluation 0.75 ('Italian', 'Vitlisa') 0.75\n",
            "Evaluation 0.25 ('Italian', 'Viberi') 0.25\n",
            "Evaluation  ('Italian', 'Yenter')\n",
            "Evaluation 1 ('Italian', 'Yarti')\n",
            "Evaluation 0.5 ('Italian', 'Yacta') 0.5\n",
            "Evaluation 0.75 ('Italian', 'Yealo') 0.75\n",
            "Evaluation 0.25 ('Italian', 'Yar') 0.25\n",
            "Evaluation  ('Czech', 'Lakha')\n",
            "Evaluation 1 ('Czech', 'Las')\n",
            "Evaluation 0.5 ('Czech', 'Liska') 0.5\n",
            "Evaluation 0.75 ('Czech', 'Lawon') 0.75\n",
            "Evaluation 0.25 ('Czech', 'Louuwas') 0.25\n",
            "Evaluation  ('Russian', 'Nakovan')\n",
            "Evaluation 1 ('Russian', 'Nartanov')\n",
            "Evaluation 0.5 ('Russian', 'Nizfikellatov') 0.5\n",
            "Evaluation 0.75 ('Russian', 'Nargontnulesam') 0.75\n",
            "Evaluation 0.25 ('Russian', 'Nempov') 0.25\n",
            "epoch 10 loss 1.888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKzm-xE6KkL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2f711c8-3506-4413-e0df-2f210fee10d1"
      },
      "source": [
        "letters[51]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Z'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIImgoLMvVw-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b36f88e7-f1b3-4d87-b64c-0faa63459828"
      },
      "source": [
        "np.random.rand()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5955402518903686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgTPi-rgGCf-"
      },
      "source": [
        "def evaluate(category_id, name='A'):\n",
        "  temp = 1.0\n",
        "  with torch.no_grad():\n",
        "    cat = categories[category_id]\n",
        "    catx = torch.tensor([category_id])\n",
        "    tensor = process_word(name)\n",
        "    state = model.initialize_state()\n",
        "\n",
        "    for i in range(tensor.size(0)):\n",
        "      y, state = model(catx, tensor[i].view(1), state, False)\n",
        "    for i in range(15):\n",
        "      _,y = y.topk(1, dim=-1)\n",
        "      if y.item()==58:\n",
        "        return cat, name\n",
        "      else:\n",
        "        name += letters[y.item()]\n",
        "      y, state = model(catx, y.view(1), state, False)\n",
        "      # y = y/temp\n",
        "      # ind = torch.multinomial(y, 1)[-1, 0].item()\n",
        "      # tensor = torch.tensor([ind])\n",
        "      # if ind==58:\n",
        "        # return cat, name\n",
        "      # name += letters[ind]\n",
        "    return cat, name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMFtZNSgPovy"
      },
      "source": [
        "def evaluate1(category_id, name='A', temp=1.0):\n",
        "  with torch.no_grad():\n",
        "    cat = categories[category_id]\n",
        "    catx = torch.tensor([category_id])\n",
        "    tensor = process_word(name)\n",
        "    state = model.initialize_state()\n",
        "\n",
        "    for i in range(tensor.size(0)):\n",
        "      y, state = model(catx, tensor[i].view(1), state, False)\n",
        "    for i in range(15):\n",
        "      y = torch.multinomial(y/temp, 1)\n",
        "      if y.item()==58:\n",
        "        return cat, name\n",
        "      else:\n",
        "        name += letters[y.item()]\n",
        "      y, state = model(catx, y.view(1), state, False)\n",
        "      # y = y/temp\n",
        "      # ind = torch.multinomial(y, 1)[-1, 0].item()\n",
        "      # tensor = torch.tensor([ind])\n",
        "      # if ind==58:\n",
        "        # return cat, name\n",
        "      # name += letters[ind]\n",
        "    return cat, name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nfCuNDHynl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e8356c9-7f20-489d-b6de-314ce31e048a"
      },
      "source": [
        "evaluate1(4, 'H')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Polish', 'Holgi')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6vW4It1NuNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2456344-f7d3-4d5a-b983-e18fc0efead2"
      },
      "source": [
        "torch.multinomial(y.exp(), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[33]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc8PwP7eoN7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5f67653-abc8-47af-d165-0a41026315ca"
      },
      "source": [
        "# cat, catx,name, tensor = get_random()\n",
        "tensor = process_word('satoshi')\n",
        "tensor\n",
        "y = model(tensor)\n",
        "_,ind = y.topk(3)\n",
        "for i in range(ind.shape[1]):\n",
        "  print(categories[ind[0][i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Japanese\n",
            "Italian\n",
            "Russian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br0qvI9WoT7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05b0edc7-55f6-4276-d212-793521e8ee2e"
      },
      "source": [
        "_,ind = y.topk(1)\n",
        "ind = ind.item()\n",
        "cat, categories[ind]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('English', 'Polish')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsyXWX0Dq2bg"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTa2zXH8jRHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d17f63c-4b81-4b47-c12c-d4378f0c1f8f"
      },
      "source": [
        "cat, catx,name, tensor = get_random()\n",
        "y = rnn(tensor)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ehm5bH-jcOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "485096c0-979b-418c-a402-b484b187ef2c"
      },
      "source": [
        "loss_fn(y.view(1,-1), catx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7988, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJEUcEXb83ME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f711922c-3875-48c9-a9e3-f6e7667a4caa"
      },
      "source": [
        "x.dtype\n",
        "y = rnn(x)\n",
        "y.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VFMdZKrjbHb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC0uSrW4dsvp"
      },
      "source": [
        "cat, catx,name, tensor = get_random()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNvOsASgSSa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d0b9571-e622-4fb0-ec06-9bb46e1d3b58"
      },
      "source": [
        "catx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SK6R2LlizYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "d505212f-49ad-49ad-e8cf-2f32bb8943ba"
      },
      "source": [
        "train_step(tensor, catx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-3a5e55953d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-f69ee7b8e116>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 932\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAPwdtWoGjbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfd49195-40e2-41eb-e70c-c6196c6faa16"
      },
      "source": [
        "target = torch.tensor(0).expand(1)\n",
        "target.size()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "loss(y.view(1, -1), target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.9066, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    }
  ]
}